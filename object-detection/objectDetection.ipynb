{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objection Detection using Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "classes = []\n",
    "\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getUnconnectedOutLayersNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595 448\n",
      "52 112\n",
      "550 399\n",
      "51 113\n",
      "601 442\n",
      "49 114\n",
      "584 445\n",
      "51 113\n",
      "559 406\n",
      "51 110\n",
      "544 437\n",
      "51 111\n",
      "547 447\n",
      "52 111\n",
      "561 442\n",
      "49 114\n",
      "555 454\n",
      "50 112\n",
      "517 378\n",
      "52 111\n",
      "500 391\n",
      "51 111\n",
      "496 389\n",
      "51 112\n",
      "523 421\n",
      "52 110\n",
      "476 409\n",
      "44 108\n",
      "548 431\n",
      "50 111\n",
      "560 420\n",
      "51 113\n",
      "556 411\n",
      "51 113\n",
      "568 418\n",
      "51 110\n",
      "554 419\n",
      "50 109\n",
      "547 384\n",
      "50 112\n"
     ]
    }
   ],
   "source": [
    "# Capture video stream from the default camera (change if needed)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video stream\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame. Exiting..\")\n",
    "    # Perform object detection on the frame\n",
    "    height, width, _ = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(layer_names)\n",
    "\n",
    "    # Process the outputs and draw bounding boxes\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:  # Adjust the confidence threshold as needed\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                print(w, h)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                break\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow(\"Object Detection\", frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
